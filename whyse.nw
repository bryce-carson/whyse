%% -*- mode: Poly-Noweb; noweb-code-mode: emacs-lisp-mode; fill-column: 72; -*-
% Copyright © 2023 Bryce Carson
\documentclass[draft,enabledeprecatedfontcommands]{report}

\title{The Implementation of WHYSE} % Codename "Wise Eel"
\author{Bryce Carson}

%%% FIXME: finduses.nw and the recognizer.nw need some tweaking to
%%% better support LISP identifiers. It may be as simple as moving `-'
%%% from SYMBOLS to ALPHANUMERIC.

%%% ---- PREAMBLE ---- %%%
\usepackage{standalone}

%% FONT
\usepackage[rm]{roboto}
\usepackage[T1]{fontenc}
\usepackage{fontspec}
\setmainfont{Eczar-Regular.otf}[BoldFont=Eczar-SemiBold.otf]

%% MARGIN
\usepackage{geometry}
 \geometry{
   top=0.625in,
   left=0.625in,
   right=0.625in,
   bottom=0.625in,
   %% "Octavo" size: https://papersizes.io/books/octavo
   %% papersize={6in, 9in}
   %% papersize={9in, 12in}
   papersize={8.5in, 11in}
 }
\usepackage{mparhack}
\usepackage{mathptmx}

%% FIXME: biblatex causes knoweb to be unable to compile. Does it work
%% with the unenhanced noweb macro package?
%% \usepackage{biblatex}
%% \addbibresource{\whyse.bib}

%%% --- NOWEB LaTeX PACKAGE --- %%%
%% \usepackage[breakcode,footnotesizecode]{knoweb}
\usepackage{noweb}
\noweboptions{smallcode,longchunks}
%% \setlength{\nwbreakcodespace}{0.2in}

%% MAYBE TODO: Modify knoweb to use the typographic conventions
%% of Bert Burgemeister's ``Common Lisp Quick Reference''
%% (http://clqr.boundp.org/clqr-letter-consec.pdf). TODO:
%% Motivating the previous todo, modify autodefs.elisp and
%% finduses.nw to work better for LISPs with multiple slots (like
%% Maclisp or Emacs Lisp). There should be no problem
%% differentiating between whyse the customization group, and
%% whyse the function, and whyse the variable. This is a
%% difficult one and probably requires manual annotation,
%% something filters should be used for after hacking on Joseph
%% S. Riel's autodefs.elisp and Noweb's finduses.nw!

%% TODO: investigate the use of the varioref, prettyref, and
%% cleveref macro packages. These packages are useful for
%% references internal to the document (cross-references), not
%% references external to the document (references). See:
%% https://texblog.org/2017/12/17/fancy-labels-and-references-in-latex/.
\usepackage[colorlinks,backref]{hyperref}

\usepackage{verbatim}
\usepackage{syntax}
\usepackage{xspace}
\usepackage{paralist}
\usepackage{color}
\usepackage{fancyvrb} % NOTE: used in the figure of the WHYSE frame layout.
\usepackage[nowatermark]{fixmetodonotes}






\pagestyle{noweb}





%%% ---- BEGINNING OF DOCUMENT ---- %%%
\begin{document}

%% \frontmatter

\maketitle

\tableofcontents

%% \mainmatter

%% MAYBE TODO: when commenting a region of LaTeX in
%% Poly-Noweb-mode the quotations should be guarded with
%% at-signs, like [[@<<name>>]]. The Emacs poly-noweb mode should
%% have syntax highlighting that does not hightlight quotations
%% within LaTeX comments. The font-locking should be aware that
%% this is a comment, so that the proper syntax highlighting is
%% applied (i.e. none is applied to the quotation, or at least it
%% is another shade of the comment syntax colouring, rather than
%% pure white like body text).

\begin{abstract}
  \textsc{(no)Web HYpertext System in Emacs (WHYSE)} is an integrated
  development environment for Noweb and \LaTeX{} within Emacs, similar to EDE
  but not sharing development principles. It is based off of \CITE{an academic
    paper written in 1991 by Brown and Czejdo}. A paper describing this
  implementation---written in Noweb and browsable, editable, and auditable with
  WHYSE, or readable in the printed form---is hoped to be submitted to \em{The
    Journal of Open Source Software (JOSS)} before the year 2024. N.B.: the
  paper will include historical information about literate programming, and
  citations (especially of those given credit in the [[@<<Commentary>>]] for
  ideating WHYSE itself).

  Users of WHYSE in Emacs are expected to be familiar with Noweb; this does not
  include how Noweb is built from source (that is arcane, supposedly). It may,
  however, include the writing of filters implemented with Sed, AWK, or other
  languages. Users must know how to write a custom command-line for noweave
  (read the manual section regarding the \texttt{-v} option). If you only know
  how to call the noweave command you're reading the wrong document. Read the
  Noweb manual first, please. Developers of WHYSE extensions should read the
  Noweb Hacker's Guide until they understand it, afterwards reading this
  documentation several times until the full implementation is understood. I
  recommend modifying the system using itself to keep organized, and writing
  literately; you'll thank yourself later for doing so.
\end{abstract}

\chapter{WHYSE Projects}\label{Projects}
The organization of this literate program is \textit{linear}, with aspects of
the program explained as the user would encounter them, more or less. A user
will read from the package description that they should call an interactive
command to create a project. The \textsc{WHYSE} application has a single
interactive command: [[whyse]]. The command loads the first element of the
customization variable [[w-registered-projects]], considering that the default
project, or it opens the ``Easy Customization Interface'' for the application's
customization group ([[M-x customize-group whyse]]): an effective prompt for the
user to enter the necessary information. If user's dislike this, they can
disable it.

A customization group for WHYSE is defined to organize its customization
variables, and these details are explained before moving on to explain the
struct used during runtime.

<<Customization and global variables>>=
(defgroup whyse nil
  "noWeb HYpertext System in Emacs"
  :tag "WHYSE"
  :group 'applications)

(defcustom w-registered-projects nil
  "This variable stores all of the projects that are known to WHYSE."
  :group 'whyse
  :type '(repeat w--project-widget)
  :require 'widget
  :tag "WHYSE Registered Projects")

@

%% NOTE: The Widget feature is required by the registered projects variable,
%% but may be redundant because the Easy Customization Interface is
%% itself implemented with The Emacs Widget Library. Requiring the
%% library may be undesirable, as @[@[(require 'widget)]] will be
%% eagerly evaluated upon Emacs' initialization when
%% @[@[w-registered-projects]] is set to its saved custom value.
%% However, there may be a good reason to eagerly evaluate that form:
%% the Widget feature will be available immediately, and widgets will be
%% used in buffers to provide TUI buttons for navigation between modules
%% of a literate program (at least, that is the design of the program at
%% this point in development), so having this feature available sooner
%% than later is okay. The feature is required by the package
%% regardless.

The [[w--project-widget]] type used for the registered projects variable
is a simple list widget containing the name of the project and a path to
its Noweb source file, along with a shell command which generates the
Noweb tool syntax for this project. Each Noweb project has a different
command-line, and some are complex enough to have a makefile, or
multiple makefiles! Noweb itself is an example of that level of
complexity. The shell command is executed by WHYSE upon loading the
project, and the standard output captured for parsing by a PEG parser.

The widget itself is explained in \ref{widgetry}.

\section{Widgetry}\label{widgetry}
<<Widgets>>=
(define-widget 'w--project-widget 'list
  "The WHYSE project widget type."
  :format "\n%v\n"
  :offset 0
  :indent 0

  ;; NOTE: the convert-widget keyword with the argument
  ;; 'widget-types-convert-widget is absolutely necessary for ARGS to be
  ;; converted to widgets.
  :convert-widget 'widget-types-convert-widget
  :args '((editable-field
           :format "%t: %v"
           :tag "Name"
           :value "")

          (file
           :tag "Noweb source file (*.nw)"
           :format "%t: %v"
           :valid-regexp ".*\\.nw$"
           :value "")

          (string
           :tag "A shell command to run a shell script to generates Noweb tool syntax"
           :format "%t: %v"
           :documentation "A shell script which will produce the
           Noweb tool syntax. Any shell commands involved with
           noweave should be included, but totex should of course
           be excluded from this script. The script should output
           the full syntax to standard output. See the Noweb
           implementation of WHYSE for explanation."
           :value "")

          (editable-list
           :tag "LaTeX sectioning commands"
           :format "%t\n%v%i\n"
           :documentation "The strings here should be the maximum length of the command
                  possible, because substrings like 'section' will not match the
                  sectioning command only. It is likely that these will have false
                  positive matches (Sectioning command might be called like
                  '\\section{}' or '\\mySectionCommand[bold]{name}'.)"
           :args ((string :tag "Sectioning command"
                          :format "%t: %v"
                          :value "\\section{"
                          ;; FIXME: even with regex-builder I can't seem
                          ;; to write a regular expression that doesn't
                          ;; reject seemingly valid strings.
                          ;; :valid-regexp "\\.*\\(\\[.*\\]\\)?{?"
                          :documentation "More than simply 'section', use '\\section{' or '\mySection[]{' at least."
                          )))
          ))

(define-widget 'w--module-header 'group
  "Code and docs module editor headerbar.

This widget represents the headerbar for the code and docs module
editor."
  <<module-header top-level>>)

@

The definition of [[<<module-header top-level>>]] is saved for later,
because the organization of the editing buffer is experimental and
therefore kept in the developer-oriented miscellany section \ref{misc}.

%% NOTE: Comments may be superfluous in a literate document like this,
%% but some effort was made to produce a readable source file regardless
%% of the conventions other literate programmers follow; other authors
%% write warnings into their tangled source files like, ``Don't read
%% this file! Read the Noweb source only!''. I don't say that,
%% especially for an Emacs application, which should always be
%% self-documenting whatever format it was distributed in: a Noweb
%% source or printed literate program, or a tangled source tarball for
%% installation on a user's machine.

%% TODO: include a customization variable that allows users to trigger
%% an error or a warning rather than opening Customize when no default
%% project is available.

An example of what the list generated from the information entered into
Customize would look like is given here for elucidation (as it would exist in a
[[custom-set-variables]] form).

\begin{verbatim}
'(w-registered-projects
  '(("noWeb HYpertext System in Emacs"
     "~/Desktop/whyse.nw"
     "make -C ~/Desktop --silent --file ~/src/whyse/Makefile tool-syntax"))
  nil
  (widget))
\end{verbatim}

The function documentation string should be expalnatory enough for the
behaviour of the [[whyse]] command.

<<WHYSE>>=
(defun whyse ()
  "Opens the default whyse project, conditionally running hooks.

Hooks are only run if a project is actually opened. If
`w-load-default-project?' and
`w-open-customize-when-no-project-defined?' are both nil then a
warning is given and hooks are not run.

When both customization variables are non-nil, or if only
`w-load-default-project?' is nil, then Customize is opened to the
whyse group."
  (interactive)
  ;; Warn the user that their customization options have made `whyse' a
  ;; no-op function.
  (when (and (not w-load-default-project?)
             (not w-open-customize-when-no-projects-defined?))
    (warn "The customization options for `whyse' have effectively disabled the `whyse' command."))
  (if-let ((w-load-default-project?)
           (default-project (cl-first w-registered-projects))
           (project (make-w-project :name (cl-first default-project)
                                    :noweb (cl-second default-project)
                                    :script (cl-third default-project)))
           (parse-tree <<parse-project-in-temp-buffer>>))
      (progn
        <<setup project database>>
        (run-hooks 'w-open-project-hook)
        ;; TODO: connection closure should be on a timer that is reset
        ;; everytime a `w-'prefixed function is called, or something.
        (emacsql-close (w-project-database-connection project)))
    (unless (not w-open-customize-when-no-projects-defined?)
      (customize-group 'whyse))))

<<Customization and global variables>>=
(defcustom w-load-default-project? t
  "Non-nil values mean the system will load the default project.

nil will cause the interactive command `whyse' to open Customize on
its group of variables."
  :type 'boolean
  :group 'whyse
  :tag "Load default project when `whyse' is invoked?")

(defcustom w-open-customize-when-no-projects-defined? t
  "Non-nil values mean the system will open Customize as necessary.

nil will cause `whyse' to simply do nothing when no project is
defined."
  :type 'boolean
  :group 'whyse
  :tag "Open Customize to the whyse group when `whyse' is invoked and no projects are defined?")
@

The structure accessed in the namesake command of the package is rather
simple. \TODO{Ensure that the previous statement in-prose [not in the
    TODO summary] is still correct.} It is defined quickly, then explained briefly.

<<WHYSE project structure>>=
(cl-defstruct w-project
  "A WHYSE project"
  ;; Fundamental
  name
  noweb
  script
  sectioning-commands-regexs
  database-file
  database-connection

  ;; Usage
  frame

  ;; Metadata
  (date-created (current-time-string))
  date-last-edited
  date-last-exported

  ;; TODO: limit with a customization variable so that it does not grow too large.
  history-sql-commands)
@

Instances of this struct are only initialized with a few values:
[[name]], [[noweb]], and [[script]]. The rest of the fields
either have default values dependent upon the input data (like
the database-file, database-connection, and date-created), or are
given values when appropriate later in operation (such as
[[date-last-exported]]) or upon initialization ([[frame]]).

Initialization when the interactive command is called is covered next;
to summarize: [[w-open-project-hook]] is run. \TODO{Describe
  initialization of the system after parsing.}

\section{Database initialization}
\TODO{finish the creation of a database. Use what I learned in the fall!}

Every project should have a database file located somewhere within the
user's Emacs directory; if the user is a Spacemacs user, then Spacemacs'
cache directory is used, otherwise the database is made in the user's
Emacs directory and not a sub-directory thereof.

The
form %% LISP form? Yes.
used to create the absolute path for the location of the
database joins three things: the user's Emacs directory, \texttt{nil} or
Spacemacs' cache directory, and the name of the project with ``.db''
appended. Note that concatenating \texttt{nil} with a string is the same
as returning the string unchanged.

<<return a filename for the project database>>=
(file-name-concat
 ;; Usually ~/.emacs.d/
 user-emacs-directory
 ;; `nil' or the Spacemacs cache directory.
 (when (file-directory-p (expand-file-name ".cache" user-emacs-directory))
   ".cache")
 ;; PROJECT-NAME.db
 (concat (w-project-name project)
         ".db"))
@

For \textsc{SQLite}, the path name of the database to connect to or
create is sufficient to establish a connection, so the next step is to
connect to the database and store the connection object in the
appropriate slot of the project struct.

<<setup project database>>=
<<create a database connection>>
<<map over SQL s-expressions, creating the tables>>
@ 

<<create a database connection>>=
(setf (w-project-database-connection project)
      (emacsql-sqlite <<return a filename for the project database>>
                      ;; TODO: make this debug log buffer into a package
                      ;; customization. NOTE: this erases the contents
                      ;; of the named buffer and then returns the buffer
                      ;; object for that buffer.
                      :debug (with-current-buffer
                                 (get-buffer-create "emacsql-sqlite-debug-log")
                               (erase-buffer)
                               (current-buffer))))
@ 

The only thing left to do is establish the schema of the tables, which
is done by mapping over several \textsc{EmacSQL} s-expressions.

%% To create an (SQLite) database from scratch for use with WHYSE, the schema
%% must be applied to the database using data definition language (DDL).
%% With the four tables created, data is provided to the database after the
%% parsing expression grammar (PEG) has finished its work on the tool
%% syntax produced by Noweave's \texttt{markup} program. The PEG and the
%% tool syntax are dealt with in \ref{PEG}.

%% TODO: ensure that this database is in 3NF and make a nice database
%% planning documents for it.
<<map over SQL s-expressions, creating the tables>>=
(mapcar (lambda (expression)
          (emacsql (w-project-database-connection project) expression))

        ;; A list of SQL s-expressions to create the tables.
        '([:create-table :if-not-exists module
           ([modulename content filename sectionname displacement
             modulenumber]
            (:primary-key [modulenumber modulename filename]))]

          [:create-table :if-not-exists parentchild
           ([parent child]
            (:primary-key [parent child]))]

          ;; NOTE: Identifier_used_in_module is a relation with the
          ;; attributes identifier_name and module_number. An identifier
          ;; can be used several different ways in each module that it
          ;; is in. It can be defined, referenced or modified. Each of
          ;; this functions correspond to different value of the
          ;; attribute type_of_usage. The type_of_usage attribute can
          ;; have three values: modified, referenced, and defined.
          ;; Line_number is an attribute of each relationship. All
          ;; attributes are included in the key.
          [:create-table :if-not-exists identifierusedinmodule
           ([identifiername modulenumber linenumber typeofusage]
            (:primary-key [identifiername modulenumber typeofusage]))]

          ;;; HOLD: the concept of "topic" is not present in Noweb, but
          ;;; is present in WEB. Consult CWEB documentation and the
          ;;; original WEB documenation to see the meaning of this
          ;;; table.
          ;; NOTE: topic_referenced_in_module is a relation with
          ;; attributes topic_name and module_number. The same topic may
          ;; be in several modules and each module can contain several
          ;; topics. Both attributes compose the primary key.
          [:create-table :if-not-exists topicreferencedinmodule
           ([topicname modulenumber]
            (:primary-key [topicname modulenumber]))]))
@





\section{Customizing the behaviour of [[whyse]] with hooks}
WHYSE is meant to be customizable, defining as little as necessary to
implement a development environment for Noweb as described by
(\CITE{Brown and Czejdo}).

<<open-project-hook>>=
(defvar w-open-project-hook '()
  "Hooks to run when `whyse' has opened a project.")
@

The default behaviour of WHYSE is to insert all the chunks of the parsed
document into a database. Before it does that it works upon the parse
tree, preparing it into a suitable format usable with EmacSQL (which the
author is aware he's stated elsewhere).

<<default hook functions>>=
(add-hook 'w-open-project-hook 'w--prepare-sexp-sql-from-file-tokens)

@ 





\chapter{Parsing project nowebs}
This section covers the parsing of the noweb tool syntax produced when
[[whyse]] executes the project's defined shell script to generate the
tool syntax.

The \textsc{peg} package provides automatic parser generation from a
formal PEG grammar. The grammar is based off of the description of the
tool syntax given in the \CITE{Noweb Hacker's Guide}.

%%% FIXME: the technobabble here is unhelpful.
%% Parsing the tool syntax allows for the generation of an
%% partially--directed graph, a digraph, of the network of chunks which
%% have hierarchical, self and non-self references, with their sequential
%% ordering and non-sequential orderings available for navigation (see
%% \href{https://www.isko.org/cyclo/hypertext#2.5}{\textsc{Intl. Soc.
%%     Knowledge Organization}} for futher information).

%% NOTE: to match the new line character in a text stream, the string
%% literal "\n" must be included. The (eol) PEG rule /tests/ for the end
%% of line by guarding the boolean return value of the standard Emacs
%% Lisp (eolp). To test if point is at the end of a line, use (eol), to
%% match the end of line, and permit parsing the next line of input,
%% include the string literal "\n".
\section{PEG rules}\label{rules}
Every character of an input text to be parsed by parsing expressions in
a PEG must be defined in terminal rules of the formal grammar. The root
rule in the grammar for Noweb tool syntax is the appropriately named
[[noweb]] rule. Beginning [[with-peg-rules]] brought into scope, the
root rule [[noweb]] is ran on the buffer containing the tool syntax
produced by the project shell script.

The grammar can be broken into five sections, each covering some part of
parsing.

<<PEG rules>>=
<<high-level Noweb tool syntax structure>>
<<files and their paths>>
<<chunks and their boundaries>>
<<quotations>>
<<keyword definitions>>
<<meta rules>>
@ 

As stated, the [[noweb]] rule defines the root expression---or starting
expression---for the grammar. The tool syntax of Noweb is simply a list
of one or more files, which are each composed of at least one chunk.
Ergo, the following [[<<high-level Noweb tool syntax structure>>]] is
defined.

<<high-level Noweb tool syntax structure>>=
;;; Overall Noweb structure
(noweb (bob) (not header) (+ file) (not trailer) (eob))
@

It is a fatal error for WHYSE if the header or trailer wrapper keywords
appear in the text it is to parse. They are totally irrelevant, and only
matter for the final back-ends (\TeX, \LaTeX, or HTML) that produce
human-readable documenation.

The grammar needs to address the fact that the syntax of the Noweb tool
format is highly line-oriented, given the influence of AWK on the design
and usage of Noweb (a historical version was entirely implemented in
AWK). The following [[<<meta rules>>]] define rules which organize the
constructs of a line-oriented, or data-oriented, syntax.

<<meta rules>>=
;; Helpers
(nl (eol) "\n")
(!eol (+ (not "\n") (any)))
(spc " ")
@

TODO: Review the following paragraph and rephrase it.

With the [[<<meta rules>>]] enabling easier definitions of what a given
``keyword'' looks like, the concept of a file needs to be defined. A
file is ``anything that looks like a file to Noweb''. However, by
default, only the chunk named ``*'' (it's chunk header is [[@<<*>>]]) is
tangled when no specific root chunk is given on the command line.

TODO: Write about the need for the overall document to be separate from
the one-or-more files specified in the document. Exempli gratia: the
current document, contained in \texttt{whyse.nw} contains two files,
though they are separately tangled: \texttt{whyse.el} and
\texttt{test-parser-with-temporary-buffer.el}. If these two files were
tangled at the same time, such that the output file discovery ability of
Noweb was used, then the there would be more than one file in the
intermediate tool syntax, but still a single preceeding documentation
chunk before the first file, and a single succeeding documentation chunk
after the last file.

<<files and their paths>>=
;; Technically, file is a tagging keyword, but that classification only
;; makes sense in the Hacker's guide, not in the syntax.
(file (bol) "@file" spc (substring path) nl
      (action (setq w--file-current-line 0))
      (list (and (+ chunk)
                 (list (or (and x-chunks i-identifiers)
                           (and i-identifiers x-chunks))))
            ;; Trailing documentation chunk and new-lines after the xref
            ;; and index.
            (opt chunk)
            (opt (+ nl)))
      `(path chunk-list -- (cons path chunk-list)))
(path (opt (or ".." ".")) (* path-component) file-name)
(path-component (and path-separator (+ [word])))
(path-separator ["\\/"])
(file-name (+ (or [word] ".")))
@

NOTE: Writing PEXes for matching file names was the most difficult part
I have encountered so far, as it has forced me to understand that a
first reading of documentation is usually not sufficient to understand a
complex library in an area of programming I have not practiced in before
(language parsing).

Because chunks must not overlap, but can nest, the beginnings of chunks
need to be pushed to the parsing stack and the end of a chunk needs to
be popped off of it. The stack pushing operations in [[kind]] and
[[ordinal]] delimit chunks by their kinds and number, and the stack
actions in the [[end]] rule check that the chunk-related tokens on the
stack are balanced.

<<chunks and their boundaries>>=
(chunk begin (list (* chunk-contents)) end)
(begin (bol) "@begin" spc kind spc ordinal (eol) nl
       (action (if (string= (cl-second peg--stack) "code")
                   (setq w--peg-parser-within-codep t))))
(end (bol) "@end" spc kind spc ordinal (eol) nl
     (action
      (setq w--peg-parser-within-codep nil))
     ;; The stack grows down and the heap grows up,
     ;; that's the yin and yang of the computer thang
     `(kind-one
       ordinal-one
       keywords
       kind-two
       ordinal-two
       --
       (if (and (= ordinal-one ordinal-two) (string= kind-one kind-two))
           (cons (cons (if (string= kind-one "code")
                           'code
                         'docs)
                       ordinal-one)
                 keywords)
         (error "Chunk nesting error encountered."))))
(ordinal (substring [0-9] (* [0-9]))
         `(number -- (string-to-number number)))
(kind (substring (or "code" "docs")))
@ 

Valid [[chunk-contents]] is somewhat confusing, because chunks
can contain many types of information other than text and new
lines. The definition of what is valid follows.

\begin{enumerate}
\item \texttt{text}
\item \texttt{nl}
\item \texttt{defn \textit{name}}
\item \texttt{use \textit{name}}
\item \texttt{line \textit{n}}
\item \texttt{language \textit{language}}
\item \texttt{index \ldots}
\item \texttt{xref \ldots}
\end{enumerate}

Any other keywords are invalid inside a code block. An example of an
invalid keyword is anything related to quotations! \textit{This
  restriction only applies to code blocks, however, and documentation
  chunks may contain quotations, of course.} As an exception, the
keywords were originally banned inside code chunks, but to parse the
noweb document in which WHYSE itself was written it needed to be
adjusted. The grammar should be studied again to ensure that textual
description and reality are in step.

%% TODO: rephrase this and ensure it is accurate. The rules for parsing
%% were modified quite significantly from the initial definition so that it
%% would ``work'', and so that \textit{whyse.nw} would be successfully
%% parsed. ``Further, the implementation was modified to accommodate the
%% parsing of the Noweb \texttt{whyse.nw} firstly.''

<<chunks and their boundaries>>=
(chunk-contents
 (or
  <<structural keywords>>
  <<tagging keywords>>
  x-notused
  <<tool errors>>))
@ 

It is easier to handle the fatal keyword appearing inside chunks when it
is a permissible keyword to appear inside a chunk; this allows the
parser to consider a chunk with fatal inside of it \textit{as a valid
  chunk}, but that does not mean that a chunk with a fatal keyword
inside it does not invalidate a Noweb, it still does: the fatal keyword
causes a fatal crash in parsing regardless. Those structural keywords
which may be used inside the contents of a chunk are given next.

<<structural keywords (except quotations)>>=
;; structural
text
nwnl ;; Noweb's @nl keyword, as differentiated from the rule nl := "\n".
defn
;;; NOTE: previously, a note on the following line incorrectly stated
;;; the `use' token was related to the `identifierusedinmodule' table,
;;; when it is actually related to the `parentchild' table.
use
@ 

All structural keywords, then, are:

<<structural keywords>>=
<<structural keywords (except quotations)>>
quotation
@ 

<<tagging keywords>>=
;; tagging
line
language
;; index
i-define-or-use
i-definitions
;; xref
x-prev-or-next-def
x-continued-definitions-of-the-current-chunk
i-usages
x-usages
x-label
x-ref
@ 

\TODO{Verify that this statement is true: ``Usually Noweb will warn a
  user that a chunk was referenced but undefined, or that there was some
  other issue with chunks.''} Sometimes, however, the system will permit
a chunk to be undefined and this leads to the only cases in the tool
syntax where it is not line-oriented. [[noidx]] will read the cross
references to other chunks and will be unable to generate the label, so
it will insert [[@notdef]] where it would otherwise upcase ``nw'' and
then insert the label. This is why [[x-undefined]] is placed among the
other [[<<tool errors>>]] keywords.

<<tool errors>>=
;; error
fatal
x-undefined
@ 

The fundamental keywords are text and nwnl (new line, per Noweb
convention). Text keywords contain source text, and any new line tokens
in the source text are replaced with the appropriate number of @nl
keywords (per convention); these are reduced to a single text token when
they are adjacent on the [[peg--stack]].

<<chunks and their boundaries>>=
(text (bol) "@text" spc (substring (* (and (not "\n") (any)))) nl
      `(txt -- (w--concatenate-text-tokens (cons 'text txt))))
(nwnl (bol) (substring "@nl") nl (action (setf w--file-current-line
                                               (1+ w--file-current-line)))
      ;; Be sure that when thinking about the symbol `nl' here that
      ;; you're not confusing it with the peg rule nl.
      `(nl -- (w--concatenate-text-tokens (cons 'nl "\n"))))
@

Nowebs are built from chunks, so the definition and usage of (i.e. references
to) a chunk are important keywords.

<<chunks and their boundaries>>=
(defn "@defn" spc (substring !eol) nl
  `(name -- (cons 'chunk name)))

;; In @<<whyse.el>>=, it leads to usages tokens like below:
;; (chunk-child-usage . "Commentary")
;; (chunk-child-usage . "Code")
(use
 (bol) "@use" spc (substring !eol) nl
 `(name --
        (if name (cons 'chunk-child-usage name)
          (error "UH-OH! There's a syntax error in the tool output!"))))
@

\begin{quotation}
  Documentation may contain text and newlines, represented by @text and
  [@nwnl]. It may also contain quoted code bracketed by @quote . . .
  @endquote. Every @quote must be terminated by an @endquote within the
  same chunk. Quoted code corresponds to the [[…]] construct in
  the noweb source.
\end{quotation}

<<quotations>>=
(quotation (bol) "@quote" nl
           (action (when w--peg-parser-within-codep
                     (error "The parser found a quotation within a code chunk. A @fatal should have been found here, but was not.")))
           (substring (+ (and (not "@endquote") (any))))
           (bol) "@endquote" nl
           `(lst -- (cons 'quotation lst)))
@

<<keyword definitions>>=
(line (bol) "@line" spc (substring ordinal) nl
      `(o -- (cons 'line o)))

(language (bol) "@language" spc (substring words-eol))
@

The indexing and cross-referencing abilities of Noweb are excellent
features which enable a reader to navigate through a printed (off-line)
or on-line version of the literate document quite nicely. These
functionalities each begin with a rule which matches only part of a line
of the tool syntax since there are many indexing and cross-referencing
keywords. The common part of each line is a rule which merely matches
the [[@index]] or [[@xref]] keyword. The rest of the lines are handled
by a list of rules in [[index-keyword]] or [[xref-keyword]].


The \textit{Noweb Hacker's Guide} lists these two lines in the ``Tagging
keywords'' table, indicating that it's unlikely (or forbidden) that the
index or xref keywords would appear alone without any subsequent
information on the same line.

\begin{quotation}
  @index ... Index information.

  @xref ... Cross-reference information
\end{quotation}

There are many keywords defined by the Noweb tool syntax, so they
are referenced in this block and defined and documented
separately. Some of these keywords are delimiters, so they are
not given full ``keyword'' status (defined as a PEX rule) but
exist as constants in the definition of a rule that defines the
grouping.

<<keyword definitions>>=
;; Index
<<indexing and cross-referencing set-off words>>
<<fundamental indexing keywords, which are restricted to within a code chunk>>
<<the index of identifiers>>
<<unsupported indexing keywords>>

;; Cross-reference
<<cross-referencing keywords>>

;; Error
<<error-causing keywords>>
@

Further keywords are categorized neatly as Indexing or
Cross--referencing keywords, so they are contained in subsections.

\subsection{indexing}
Indexing keywords, both those used within chunks and those used outside
of chunks, are defined in this section. The [[<<fundamental indexing
keywords, which are restricted to within a code chunk>>]], index
definitions or usages of identifiers and track the definitions of
identifiers in a chunk and the usages of identifiers in a chunk. They
may seem redundant, but are not; the Noweb Hacker's Guide offers a
better explanation of the differences.

<<indexing and cross-referencing set-off words>>=
(idx (bol) "@index" spc)
(xr (bol) "@xref" spc)

<<fundamental indexing keywords, which are restricted to within a code chunk>>=
(i-define-or-use
 idx
 (substring (or "defn" "use")) spc (substring !eol) nl
 (action
  (unless w--peg-parser-within-codep
      (error "WHYSE parse error: index definition or index usage occurred outside of a code chunk.")))
 `(s1 s2 -- (cons (make-symbol s1) s2)))

<<identifiers defined in a chunk>>
<<identifiers used in a chunk>>

<<identifiers defined in a chunk>>=
(i-definitions idx "begindefs" nl
               (list (+ (and (+ i-isused) i-defitem)))
               idx "enddefs" nl
               `(definitions -- (cons 'definitions definitions)))
(i-isused idx (substring "isused") spc (substring label) nl
          `(u l -- (cons 'used! l)))
(i-defitem idx (substring "defitem") spc (substring !eol) nl
           `(d i -- (cons 'def-item i)))

<<identifiers used in a chunk>>=
(i-usages idx "beginuses" nl
          (list (+ (and (+ i-isdefined) i-useitem)))
          idx "enduses" nl
          `(usages -- (cons 'usages usages)))
(i-isdefined idx (substring "isdefined" spc label) nl)
(i-useitem idx (substring "useitem" spc !eol) nl) ;; !eol :== ident
@

The summary index of identifiers is a file--specific set of keywords.
The index lists all identifiers defined in the file (at least all of
those recognized by the autodefinitions filter).

<<the index of identifiers>>=
(i-identifiers idx "beginindex" nl
               (list (+ i-entry))
               idx "endindex" nl
               `(l -- (cons 'i-identifiers l)))
(i-entry idx "entrybegin" spc (substring label spc !eol) nl
         (list (+ (or i-entrydefn i-entryuse)))
         idx "entryend" nl
         `(entry-label lst -- (cons 'entry-label lst)))
(i-entrydefn idx (substring "entrydefn") spc (substring label) nl
             `(defn label -- (cons 'defn label)))
(i-entryuse idx (substring "entryuse") spc (substring label) nl
            `(use lst -- (cons 'use lst)))
@

The following chunk's name is documentation enough for the purposes of
WHYSE. See the Noweb Hacker's Guide for more information.

[[@index nl]] was deprecated in Noweb 2.10, and [[@index localdefn]] is
not widely used (assumedly) nor well-documented, so it is unsupported by
WHYSE (contributions for improved support are welcomed).

<<unsupported indexing keywords>>=
;; @index nl was deprecated in Noweb 2.10, and @index localdefn is not
;; widely used (assumedly) nor well-documented, so it is unsupported by
;; WHYSE (contributions for improved support are welcomed).
(i-localdefn idx "localdefn" spc !eol nl)
(i-nl idx "nl" spc !eol nl
      (action (error <<index nl error message>>)))
@

\subsection{cross referencing}
<<cross-referencing keywords>>=
(x-label xr (substring "label" spc label) nl
         `(substr -- (cons 'x-label (cadr (split-string substr)))))
(x-ref xr (substring "ref" spc label) nl
       `(substr --  (cons 'ref (cadr (split-string substr)))))

;; FIXME: improve the error handling at this point. It is not fragile
;; any longer, becasue most things are ignored and this is hackish;
;; however, the message reporting is not too helpful. It would be nice
;; to have _only_ the chunk name reported, and formatted with @<< and >>.
;;; Reproduction steps: make a reference to an undefined code chunk
;;; within another code chunk. For fixing this issue, undefined code
;;; chunks should also be referenced within quotations in documentation.
(x-undefined
 xr (or "ref" "chunkbegin") spc
 (guard
  (if (string= "nw@notdef"
               (buffer-substring-no-properties (point) (+ 9 (point))))
      (error (format "%s: %s: %s:\n@<@<%s>>"
                     "WHYSE"
                     "nw@notdef detected"
                     "an undefined chunk was referenced"
                     (buffer-substring-no-properties (progn (forward-line) (point))
                                                     (end-of-line)))))))

(x-prev-or-next-def
 xr (substring (or "nextdef" "prevdef")) spc (substring label) nl
 `(previous-or-next-chunk-defn label -- (cons (make-symbol previous-or-next-chunk-defn) label)))

(x-continued-definitions-of-the-current-chunk
 xr "begindefs" nl
 (list (+ (and xr (substring "defitem") spc (substring label) nl)))
 xr "enddefs" nl)

(x-usages
 xr "beginuses" nl
 (list (+ (and xr "useitem" spc (substring label) nl)))
 xr "enduses" nl)

(x-notused xr "notused" spc (substring !eol) nl
           `(name -- (cons 'unused! name)))
(x-chunks nwnl
          nwnl
          xr "beginchunks" nl
          (list (+ x-chunk))
          xr "endchunks" nl
          `(l -- (cons 'x-chunks l)))
(x-chunk xr "chunkbegin" spc (substring label) spc (substring !eol) nl
         (list (+ (list (and xr
                             (substring (or "chunkuse" "chunkdefn"))
                             `(chunk-usage-or-definition -- (make-symbol chunk-usage-or-definition))
                             spc
                             (substring label)
                             nl))))
         xr "chunkend" nl)

;; Associates label with tag (@xref tag $LABEL $TAG)
(x-tag xr "tag" spc label spc !eol nl)
(label (+ (or "-" [alnum]))) ;; A label never contains whitespace.

<<error-causing keywords>>=
;; User-errors (header and trailer) and tool-error (fatal)
;; Header and trailer's further text is irrelevant for parsing, because they cause errors.
(header (bol) "@header" ;; formatter options
        (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(trailer (bol) "@trailer" ;; formatter
         (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(fatal (bol) "@fatal"
       (action (error "[FATAL] There was a fatal error in the pipeline. Stash the work area and submit a bug report against Noweb, WHYSE, and other relevant tools.")))
@ 

<<index nl error message>>=
(string-join
 '("\"@index nl\" detected."
  "This indicates hand-written @ %def syntax in the Noweb source."
  "This syntax was deprecated in Noweb 2.10, and is entirely unsupported."
  "Write an autodefs AWK script for the language you are using.")
 "\n")
@ 

%%  NOTE: it would be helpful to construct this sort of parse tree at
%%  the CHUNK level, and this information can be directly sent to the
%%  database.
%% `((n . ,n)
%%   (name . ,substr)
%%   ;; Displacement: count of @nl encountered in this file so far.
%%   (offset . ,offset)
%%   (file . ,file)
%%   (section . ,section)) ;; Discover a single LaTeX sectioning command
%%                         ;; in the @text commands which are prior to
%%                         ;; this module's definition, as that is the
%%                         ;; direct parent section of this module.
%%  SQL attributes in the `module' table
%% module_number; module_name; displacement; file_name; section_name

%% The definition of a Noweb file, given by Ramsey, is simply a file
%% containing one or more chunks; minimally, a Noweb file will contain the
%% default documentation chunk.

%% To summarize this section, since it is longer than the previous section,
%% the object is to convert the noweb document to tool syntax and parse it
%% with the peg parser.

%% In more explicit words, this section describes the actions that occur
%% when a user invokes [[whyse]] interactively (with \textit{M-x}) and the
%% preconditions have been met; the [[whyse]] function has already been
%% introduced, and only the ``meaty'' business end of its operation has
%% been left undefined until now. Ergo, [[w-with-project]] gathers together
%% the functionality that converts a Noweb to its tool syntax with a
%% project's specified shell script, and parses the text before the next
%% section of body forms is executed. Those send the parsed text to the
%% database, and finally create the atomic window for the IDE in the active
%% frame.

%% In earlier development versions the following function body was
%% referenced with noweb chunks rather than being defined as a function,
%% however it was decided that implementing this as a function allowed a
%% user-suggestion for an API-like function that was planned for
%% implementation anyways. Now it is a function, satisfying internal and
%% API needs.

<<parse-project-in-temp-buffer>>=
(with-temp-buffer
  (insert (shell-command-to-string (w-project-script project)))
  (goto-char (point-min))
  (w--parse-current-buffer-with-rules))

<<with-project>>=
;; TODO: understand how and why this macro works like
;; `with-temp-buffer'; I only copied a couple things from the defintion
;; of that macro, but I don't yet understand its definition fully. I
;; will need to before I really start to understand Emacs Lisp. I do
;; understand enough, but there is a lot more to know. A whole lot.
(defmacro w-with-project (project &rest body)
  (declare (indent 0) (indent 2) (debug t))
  "Evaluates BODY with PROJECT in scope. This is like `let' except
it doesn't bind arbitrary values to arbitrary symbols. PROJECT is
taken as the symbol `project' during evaluation of BODY.

PROJECT is in scope because it is an argument of this macro. This
may or may not work as expected."
  (eval `(progn ,@body)))

<<buffer parsing function>>=
;; FIXME: the current parse tree contains a `nil' after the chunk type
;; and number assoc, and that needs to be analyzed. Why is this `nil' in
;; the stack? I assume and believe it is because of the collapsing of
;; stringy tokens; when a token should be put back onto the stack it may
;; also be putting a `nil' onto the stack in the first call to the
;; function.
;;;; Parsing expression grammar (PEG) rules
(defun w--parse-current-buffer-with-rules ()
  "Parse the current buffer with the PEG defined for Noweb tool syntax."
  (with-peg-rules
      (<<PEG rules>>)
    (let (w--peg-parser-within-codep
          (w--first-stringy-token? t))
      (peg-run (peg noweb) #'w--parse-failure-function))))

(defun w--parse-failure-function (lst)
  (setq w--parse-success nil)
  (pop-to-buffer (clone-buffer))
  (save-excursion
    (put-text-property (point) (point-min)
                       'face 'success)

    (put-text-property (point) (point-max)
                       'face 'error)

    (goto-char (point-max))
    (message "PEXes which failed:\n%S" lst)))
@ 

<<Customization and global variables>>=
(defvar w--parse-success t
  "The success or failure of the last parsing of noweb tool syntax.")
@ 





\chapter{Processing parsed nowebs into SQL}\label{processing lists}
This section covers how the parsed text generated in the last section is
processed, creating a series of SQL statements that will be executed by
SQLite using the interface provided by the EmacSQL package.

First, the overall structure of the parsed text should be diagrammed.
The parse tree is a list of noweb documents, each being a list
themselves. The first atom of an inner list, corresonding to a document,
is the filename of that document (hopefully the same filename as passed
on the commmand-line elsewhere when the document is used).

Deeper, each document-list contains as the second atom a list of its
contents, which is an association list thereof. Each association in the
alist is bewteen the symbol relating to the rule that generated the cons
cell, and the contents appropriate to the symbol.

\section{Processing}
There are many steps to compiling the parse tree into SQL. The first
step is to ensure the association lists in the parse tree are in a
format that is acceptable to built-in Emacs Lisp functions; this will
make it easier to navigate the tree and transform it.
%% FIXME: is it really true, and does it make sense for
%% what I'm actually doing, or am I using the concept/name wrong?
Other texts call this manipulation of the parse tree ``list
destructuring'';
%% 
it could be thought of as code generation, since the data is used to
generate DML which is partly code and partly data.

%% FIXME 2024-08-10 what the fuck am I saying here?
Some associations are reductions from the initial parse tree---which
thanks to the \textsc{peg} package and \em{PEG parsing in general}---are
not reduced in a second step. Modifications to the parsing procedure can
occur directly without losing information, and thanks to literate
programming should be easy for advanced users.

The initial parse tree begins like the one below.

\begin{verbatim}
'((noweb-document-one
   ((docs . 0)
    (text . "\tex{} is cool!"))
   ((code . 1)
    (text . "(message \"LISP is awesome!\")")))
  (noweb-document-two
   ((code . 0)
    (text . "asdf is a system definition format in Common LISP,"))
    (nwnl . "\n")
    (text . "and I like to use it.")
   ((code . 1)
    (text . "jkl; is the right-handed corollary of asdf."))
   ((docs . 2)
    (text . "\latex{} is great!"))
   ((docs . 3)
    (text . "Noweb, written by Norman Ramsey is sweet!"))))
\end{verbatim}

The reductions which occur during parsing make chunk zero of the second
noweb document look like this in the final result.

\begin{verbatim}
((code . 0)
 (text .
  "asdf is a system definition format in Common LISP,
  and I like to use it."))
\end{verbatim}

The new result is much easier to use as data for other programs (SQL
in this case). In the verbatim text a literal newline was inserted
rather than retaining the escape sequence, which is exactly what happens
in the reduction step as well. The next subsection discusses the details
of how the reduction in complexity exampled above is achieved.

\subsection{Reducing complexity in the alist}
The first step in making the parse tree navigable for other programs is
collapsing adjacent ``stringy'' tokens into single [[text]] tokens. The
output tool syntax of notangle, and the parse tree resulting from the
PEG, (breifly) contain individual text tokens for fragments of whole
text lines and form feed characters. These tokens exist because the
cross-referencing tokens fragment the text lines, and new lines in the
noweb document are treated specially to facilitate this fragmentation.

A small quote from the tool syntax of a development version of
\textsc{WHYSE} is shown in this example in its parsed form. However,
during actual parsing these adjacent tokens are \em{immediately
  collapsed} into singular tokens.

\begin{verbatim}
(text . "  and \textsc{Noweb}'s \texttt{finduses.nw}!")
(nwnl . "@nl")
(text . "\end{enumerate}")
(nwnl . "@nl")
(text . "")
(nwnl . "@nl")
\end{verbatim}

To collapse these tokens into a single text token the
\texttt{peg--stack} must be manipulated carefully. It isn't advisable to
manipulate this variable in the course of a PEG grammar's actions. There
is a use case for it when the previous rules and actions won't
accommodate the necessary action without refactoring a larger part of the
grammar. In this development version that is not a goal; basic
functionality is sought after, not robustness or beauty, so hacking the
desired behaviour together quickly is better.

[[w--nth-chunk-of-nth-noweb-document]] retrieves the parse tree for the nth
noweb document, which in the case of [[whyse.nw]] is the parse tree of
the zeroth-indexed document. It's quite a simple function. To obtain a
given chunk of this document from the parse tree the result of the
function is called with [[nth]] and the index of the chunk.

<<functions for navigating WHYSE parse trees>>=
(defun w--nth-document-file-name (nth-document parse-tree)
  "Return the file name of the nth-indexed document in the parse tree.

For the first document in the parse tree, that is the
zeroth-indexed document."
  (cl-first (nth nth-document parse-tree)))

(defun w--nth-document (nth-document parse-tree)
  "Return the subtree of the nth-indexed document in the parse tree."
  (cl-second (nth nth-document parse-tree)))

(defun w--nth-chunk-of-document (n document)
  "Return the subtree for the Nth chunk of a noweb document parse subtree."
  (nth n document))

(defun w--chunk-number (chunk)
  "Return the chunk number of CHUNK."
  (or (cdr (assq 'code chunk))
      (cdr (assq 'docs chunk))))

(defun w--nth-chunk-of-nth-noweb-document (nth-chunk nth-document parse-tree)
  (w--nth-chunk-of-document nth-chunk (w--nth-document nth-document parse-tree)))

(defun w--chunk-text (chunk)
  "Join all the strings returned from the collection in the loop,
and return the single string."
  (string-join
   (cl-loop for elt in chunk collect
            (when (and (listp elt) (equal 'text (car elt)))
              (cdr elt)))
   ""))

(defun w--chunk-name (chunk)
  "Return non-nil if CHUNK is a code chunk, and thereby has a name.

The return value, if non-nil, is actually the name of the chunk."
  (if-let ((name (assq 'chunk chunk)))
      (cdr name)))

@ 

\TODO{Place the insertion of the functions into the code chunk better.}

<<Code>>=
<<functions for navigating WHYSE parse trees>>
<<functions to collapse text and newline tokens into their largest possible form>>
@

<<functions to collapse text and newline tokens into their largest possible form>>=
(defun w--concatenate-text-tokens (new-token)
  "Join the values of two text token associations in a two-element token alist.

If the two associations shouldn't be joined, return them to the stack."
  (prog1
      ;; Concatenation only occurs when the previous token examined was
      ;; a text or nwnl token, ergo there must have been a text or nwnl
      ;; token previously examined for any concatenation to occur. When
      ;; no such token has been examined immediately return the
      ;; (stringy) token recieved and indicate it must have been a
      ;; stringy token by chaning the value of `w--first-stringy-token?'
      ;; accordingly. Subsequent runs will then operate on potential
      ;; pairs of stringy tokens.
      (if-let ((not-first-stringy-token? (not w--first-stringy-token?))
               (previous-token  (pop peg--stack))
               ;; The previous token cannot be a text or nwnl token if
               ;; it is not a list, and checking prevents causing an
               ;; error by taking the `car' of a non-list token, e.g. the
               ;; filename token.
               (previous-token-is-alist?
                (prog1 (and (listp previous-token)
                            (listp new-token)
                            (or (assoc 'text `(,new-token))
                                (assoc 'nl `(,new-token)))
                            (or (assoc 'text `(,previous-token))
                                (assoc 'nl `(,previous-token)))))))
          ;; Join the association's values and let the caller push a single
          ;; token back onto the `peg--stack'.
          (cons 'text (format "%s%s" (cdr previous-token)
                              (cdr new-token)))

        ;; Push the previous token back to the `peg--stack', and let the
        ;; caller push the new token to that stack.
        (push previous-token peg--stack)
        new-token)
    (when w--first-stringy-token? (setq w--first-stringy-token? nil))))

@

\TODO{\em{Better} document the functionality of the default hook
  function: [[w--prepare-sexp-sql-from-file-tokens]]. The current
  explanation is a copy of the brief explanation in the hook
  documentation string.}

The `parse-tree' from the lexical environment (or scope, given
that WHYSE is not implemented with lexical binding) is mapped
over until every file token has been processed and records have
been inserted into all four tables of the database.

<<default hook functions>>=
(defun w--prepare-sexp-sql-from-file-tokens ()
  "Prepare an s-expression of SQL statements for `emacsql'.

The `parse-tree' from the lexical environment (or scope, given
that WHYSE is not implemented with lexical binding) is mapped
over until every file token has been processed and records have
been inserted into all four tables of the database.

This hook depends on this object being in scope: `parse-tree'.
That object is in scope when this hook runs with the default
implementation of `whyse'. (This is not meant to imply other
implementations exist [yet], only that hacked up installations
won't operate with any guarantees or according to the original
documentation. You know that, though, because you're reading the
source code and documentation for the original right now, and it
should be obvious that changing the source code should have been
accompanied with changes in the documentation.)"
  (mapcar
   (lambda (file-token)
     (let* ((file-name (car file-token))
            (chunks (cdr file-token))
            (modules (vector
                      :insert :into 'module
                      :values (mapcar #'w--vectorize-chunk-data chunks)
                      :on-conflict-do-nothing))
            (parent-child (vector
                           :insert :into 'parentchild
                           :values (w--parent-child-relationships)
                           :on-conflict-do-nothing))
            (connection (w-project-database-connection project)))
       (mapcar (lambda (seql) (emacsql connection seql))
               (list modules
                     parent-child
                     ;; identifier-used-in-module
                     ;; topic-referenced-in-module
                     ))))
   parse-tree))

(defun w--vectorize-chunk-data (chunk)
  "Convert an individual chunk to a vector of objects.

NOTE: order of arguments: [module-name module-text file-name
section displacement module-number]"
  (let ((chunk-name (w--chunk-name chunk)))
    (vector chunk-name
            (w--chunk-text chunk)
            file-name
            (when chunk-name
              (w--chunk-section chunk-name))
            nil
            (w--chunk-number chunk))))

(defun w--parent-child-relationships ()
  "Make a list of vectors of parent-child relationships.

The elements are taken from applying `w--get-chunk-uses-of-chunks' to
every chunk in the noweb."
  (apply #'append (cl-mapcar #'w--get-chunk-uses-of-chunks chunks)))

(defun w--get-chunk-uses-of-chunks (chunk)
  "Make a list of vectors of parent-child relationships.

The parent is CHUNK, and the first element of each vector in the
list will be the number of this chunk. The chunks this chunk uses
will be named in the vectors in the returned list."
  (with-temp-buffer
    (let* ((iter 0)
           (parent-uses-child (list nil))
           (chunk-number (assoc-default 'code chunk))
           (chunk-formatted (format "%S" chunk)))
      (insert chunk-formatted)
      (goto-char (point-min))
      (cl-remove
       nil
       (cl-mapcar (lambda (assoc)
                    (when (equal (car assoc) 'chunk-child-usage)
                      (vconcat (list (number-to-string chunk-number)
                                     (cdr assoc)))))
                  chunk)))))

@

When the SEQL (S-EXP SQL) has been compiled, it should be logged. This
might be better controlled with DCL (the data control langauge
featureset of SQL). \TODO{Make the number of entries in this history
  list customizable, limited to some given number or a default of one
  hundred.} The history of SEQL statements compiled is treated like a
stack, with the newest statement being the first element of the list. A
shoddy implementation of a ``stack-based history'' is given next.

<<push the compiled SQL to the database and to the history stack>>=
;; NOTE: the result of evaluating the SQL is pushed to the history stack
;; alongside the SQL that was executed.
(cl-pushnew (cons (emacsql (w-project-database-connection default-project)
                           compiled-parse-tree)
                  . compiled-parse-tree)
            (w-project-history-sql-commands default-project))
@





\subsection{finding the section title of a chunk}
<<Code>>=
<<find section title>>

<<find section title>>=
;; TODO 2024-05-13: this function is really rough. It still needs a
;; working algorithm to search through the noweb text to find the
;; section that a chunk belongs to. I think that searching for all of
;; the sections that preceed a chunk definition will be necessary before
;; finding the last section command that preceeds a chunk (thereby
;; finding the section the chunk belongs to). There may be a better
;; algorithm; this is the first algorithm I thought of to find the
;; section that a chunk belongs to regardless of the regular expression
;; used.
;;
;; Another algorithm might use Emacs Lisp regular expressions to search
;; for the first match to any of the set of regular expressions that
;; would search for a given sectioning command.
;;
;; For now, I trust the Emacs Lisp manual when it says that `regex-opt'
;; is efficient; it is damned convenient right now.
(defun w--chunk-section (chunk-name)
  (with-temp-buffer
    (insert-file-contents (w-project-noweb project))
    (re-search-forward
     ;; It is an error if no chunks are found.
     (regexp-opt (list (concat "<" "<" chunk-name ">" ">" "="))))
    (re-search-backward
     (regexp-opt (w-project-sectioning-commands-regexs project))
     ;; It is not an error if no section is found because sectioning is
     ;; entirely optional in a literate document with LaTeX.
     nil t)
    (buffer-substring (line-beginning-position) (line-end-position))))
@ 

While it's certain that some of the data from a search operation are
markers of a match (some of them are non-nil), substrings corresponding
to the used chunk name in the current chunk are appended to a list that
is ultimately returned.

\subsection{Determining parent-child relationships}
There needs to be a function which can take a generalizable
approach to determining the name of a section defined by any
possible sectioning command. To easily do that a function could
be provided by the user for any sectioning commands that are
exotic, and those functions will accommodate the \LaTeX{} command
while the calling function will handle finding them and
collecting their output.

%% FIXME 2024-08-10: what is this and why is it here? It seems out of place.
\begin{verbatim*}
  ((code . 32)
   (x-label . "NW2ucZJx-3LzQog-2")
   (ref . "NW2ucZJx-3LzQog-1")
   (chunk . "chunks and their bou...")
   (prevdef . "NW2ucZJx-3LzQog-1")
   (nextdef . "NW2ucZJx-3LzQog-3")
   (text . "\n(chunk-contents\n (o...")
   (x-label . "NW2ucZJx-3LzQog-2-u1")
   (ref . "NW2ucZJx-2ZphFz-1")
   (chunk-child-usage . "structural keywords")
   (text . "\n  ")
   (x-label . "NW2ucZJx-3LzQog-2-u2")
   (ref . "NW2ucZJx-44iV1g-1")
   (chunk-child-usage . "tagging keywords")
   (text . "\n  x-notused\n  ")
   (x-label . "NW2ucZJx-3LzQog-2-u3")
   (ref . "NW2ucZJx-1ZiKLq-1")
   (chunk-child-usage . "tool errors")
   (text . "))\n"))
\end{verbatim*}

<<collect child chunk uses>>=
(with-temp-buffer
  (let* ((iter 0)
         (parent-uses-child (list nil))
         (chunk-number (assoc-default 'code chunk))
         (chunk-formatted (format "%S" chunk)))
    (insert chunk-formatted)
    (goto-char (point-min))
    (cl-remove
     nil
     (cl-mapcar (lambda (assoc)
                  (when (equal (car assoc) 'chunk-child-usage)
                    (vconcat (list chunk-number (cdr assoc)))))
                chunk))))
@ 





\appendix





\chapter{Packaging whyse}
Installing an Emacs Lisp package is quite easy if the system is
distributed through the GNU Emacs Lisp Package Archive (GNU ELPA), and
only slightly less easy if it is distributed through MELPA
(Milkypostman's Emacs Lisp Package Archive). Other package archives have
existed, but they are all ephemeral. The most popular alternative to GNU
ELPA, Non-GNU ELPA, and MELPA is direct distribution of files through
Git servers and the use of a package by the end user to install directly
from such.

This software is in-development, so it will only be distributed directly
through Git.

WHYSE follows the form of ``simple'', single-file packages documented in
the Emacs Lisp Reference Manual. The package file, \texttt{whyse.el}, is
emitted by \texttt{notangle} which is called by the Makefile in every
target but [[clean]]. All source development occurs in \texttt{whyse.nw}
using \textsc{Polymode}.

The makefile distributed alongside whyse.nw in the tarball contains the
command-line used to tangle and weave WHYSE.

<<whyse.el>>=
<<Emacs Lisp package headers>>
<<Licensing and copyright>>
<<Commentary>>
<<Code>>
<<provide the whyse feature and list the file local variables>>
@

<<Emacs Lisp package headers>>=
;;; whyse.el --- noWeb HYpertext System in Emacs -*- lexical-binding: nil -*-
;; Yes, you read that right: no lexical binding in this file.

;; Copyright © 2023 Bryce Carson

;; Author: Bryce Carson <bcars268@mtroyal.ca>
;; Created 2023-06-18
;; Keywords: tools tex hypermedia
;; URL: https://github.com/bryce-carson/whyse

;; This file is not part of GNU Emacs.

<<whyse-pkg.el>>=
(define-package "whyse" "0.1" "noWeb HYpertext System in Emacs"
  '(<<required packages>>))
@

The following chunk lists the [[<<required packages>>]]; as of
[[whyse-0.1-devel]] the only required packages are [[peg]] and
[[cl-lib]], [[emacsql]].

<<required packages>>=
(emacs "25.1")
(emacsql "20230220")
(peg "1.0.1")
(cl-lib "1.0")
@

The license text was included in this document using its \LaTeX{} form
in the License section at the end of this document.

<<Licensing and copyright>>=
;; This program is free software: you can redistribute it and/or
;; modify it under the terms of the GNU General Public License as
;; published by the Free Software Foundation, either version 3 of the
;; License, or (at your option) any later version.

;; This program is distributed in the hope that it will be useful, but
;; WITHOUT ANY WARRANTY; without even the implied warranty of
;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
;; General Public License for more details.

;; You should have received a copy of the GNU General Public License
;; along with this program. If not, see
;; <https://www.gnu.org/licenses/>.

<<Commentary>>=
;;; Commentary:
;; WHYSE was described by Brown and Czedjo in _A Hypertext for Literate
;; Programming_ (1991).
;;
;; Brown, M., Czejdo, B. (1991). A hypertext for literate programming.
;;    In: Akl, S.G., Fiala, F., Koczkodaj, W.W. (eds) Advances in
;;    Computing and Information — ICCI '90. ICCI 1990. Lecture Notes in
;;    Computer Science, vol 468. Springer, Berlin, Heidelberg.
;;    https://doi-org.libproxy.mtroyal.ca/10.1007/3-540-53504-7_82.
;;
;; A paper describing this implementation---written in Noweb and browsable,
;; editable, and auditable with WHYSE, or readable in the printed form---is
;; hoped to be submitted to The Journal of Open Source Software (JOSS)
;; before the year 2024. N.B.: the paper will include historical
;; information about literate programming, and citations (especially
;; of those given credit here for ideating WHYSE itself).

<<Code>>=
;;; Code:
;;;; Compiler directives
(eval-when-compile (require 'wid-edit))

;;;; Internals
<<Customization and global variables>>
<<Widgets>>
<<WHYSE project structure>>
<<with-project>>
<<buffer parsing function>>
<<open-project-hook>>
<<default hook functions>>

;;;; Commands
;;;###autoload
<<WHYSE>>

<<provide the whyse feature and list the file local variables>>=
(provide 'whyse)

;; Local Variables:
;; mode: emacs-lisp
;; no-byte-compile: t
;; no-native-compile: t
;; End:
@ 





\newpage
\chapter{TESTING}
\TODO{Adopt the ERT (Emacs Regression Tests) package to test
  WHYSE features as they are developed and become featureful. When a
  feature is implemented a test should be written which conforms to the
  current documentation so that regressions can be caught when changes are
  made.}

\TODO{Adopt/use [[makem.sh]], by ``alphapapa''.}

\section{Parsing tool syntax within a temporary buffer}
<<test-parser-with-temporary-buffer.el>>=
;; -*- lexical-binding: nil; -*-
(defvar w--parse-success t
  "A simple boolean regarding the success or fialure of the last
  attempt to parse a buffer of Noweb tool syntax.")

<<buffer parsing function>>
(with-temp-buffer
  (insert (shell-command-to-string
           "make --silent --file ~/src/whyse/Makefile tool-syntax"))
  (goto-char (point-min))
  (w--parse-current-buffer-with-rules))

;; Local Variables:
;; mode: lisp-interaction
;; no-byte-compile: t
;; no-native-compile: t
;; eval: (read-only-mode)
;; End:
@










%% \backmatter
\chapter{Indices}

\section{Chunks}
\nowebchunks

\section{Identifiers}
\nowebindex

\listofnotes

\section{Miscellaneous code and functions useful for development and debugging}\label{misc}
<<Code>>=
(defun w--log-in-buffer (buffer-name &rest body)
  "In a new buffer named BUFFER-NAME, insert the value of evaluating BODY."
  (save-mark-and-excursion
    (with-current-buffer
        (generate-new-buffer buffer-name)
      (insert (format-message "%S" body)))))

<<module-header top-level>>
@

The top-level of the module header is defined here now.

Code modules have names, but documentation modules only sometimes have
sections. Sometimes a documentation module doesn't have a section
because the definition of one or more sections occur within it, and
therefore a section cannot apply to it by reason of occurring before the
beginning of the module. Therefore the headerbar must have a section
within it for holding a program code module name or \LaTeX{} section
name. Additionally it must also have an area to contain further buttons.
It makes sense to define, loosely, a left, right, and center area to be
filled with other widgets (which will inherit widths of the area).

<<module-header top-level>>=
:width (buffer-size)
:tag "🍫"
:format "%t%v"
;; :keymap w-widget-headerbar-map
@ 

A keymap provides for handling keyboard and mouse events.

<<Code>>= 
<<module-header keymap>>
<<module-header keymap>>=
@ 

<<module-header top-level>>=
:value '(module-header-left module-header-center module-header-right)
@ 

<<Code>>=
<<module-header-left>>
<<module-header-center>>
<<module-header-right>>
@ 

<<module-header-left>>=
(define-widget 'w--module-header-left 'group
  "DOCSTRING"
  (link :format "%t"
        :tag (format "@<<%s>>%s%s%d"
                     module-name
                     addition?
                     modified?
                     module-number)))

<<module-header-center>>=
(define-widget 'w--module-header-center 'group
  "DOCSTRING"
  '((item :tag "module")))

<<module-header-right>>=
(define-widget 'w--module-header-right 'group
  "DOCSTRING"
  '((item :tag "module")))

@

\chapter{License}
\input{gpl-3.0.tex}

\end{document}
%%% ---- END OF FILE ---- %%%
%%% ---- IGNORED ---- %%%%
